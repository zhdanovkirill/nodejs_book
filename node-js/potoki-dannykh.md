---
description: Потоки для читання/запису та перетворення даних
---

# Lesson 2 - Потоки данных

## Потоки для читання/запису та перетворення даних

Вся концепція роботи потоків полягає у передачі даних між програмами в операціях введення/виводу. Використання потоків дозволяє програмі бути незалежною і поєднуватися з іншими програмами для створення більш складної системи.

Обмін даними здійснюється частинами, не чекаючи повного завантаження, що дозволяє ефективно використовувати оперативну пам'ять.

<figure><img src="https://lh5.googleusercontent.com/4SPtjDmcBEn4likxNloX1GKHFop8KwPcbCEMI9Cj_Eu6Vinbsk2hH-49jV32GZh0EUCL_wp7ZYyjH6U3HItrFFO4OhbJ03p20P5Qb7ncK-8y1M_WxDxzJ389JwEpzF8usNlVHQ7AQwfEd2oT4fPqgrW6kgEuYduQz86ckJF6cmnXE_KWnHt_VQ4aEQ" alt=""><figcaption></figcaption></figure>

Наприклад, потрібно знайти певний рядок у файлі великого обсягу. Використання потоку дозволяє отримувати дані частинами і шукати необхідний рядок у цих частинах, при збігу подальше читання файлу можна припинити, заощадивши при цьому час і продуктивні ресурси.

{% hint style="info" %}
За роботу з потоками Node.js відповідає вбудований модуль [**Stream**](https://nodejs.org/api/stream.html#stream), причому всі екземпляри об'єктів потоків є одночасно і екземплярами класу **EventEmitter,** що дозволяє ініціювати і обробляти події.
{% endhint %}

У Node.js є такі потоки:

* **Readable** - потік читання, що отримує дані з переданого джерела (наприклад, читання з файлу)**;**
* **Writable** - потік запису даних (наприклад, збереження даних у файл);
* **Duplex** - потік, що одночасно реалізує і читання, і запис;
* **Transform** - дуплексні потоки, які можуть змінювати або перетворювати дані в міру їх запису та читання.

### Потік Readable

Потік Readable відповідає за читання даних із певного джерела. Приклади потоків читання:

* отримання сервером HTTP запиту;
* отримання клієнтом відповіді на надісланий HTTP запит;
* читання із файлу;
* отримання даних із сокетів тощо;
* потік Readable працює в одному з двох режимів: flowing (процес отримання даних) і paused (режим очікування).

За замовчуванням всі потоки читання починають працювати з режим очікування. Щоб почати читання з джерела, необхідно додати обробник події data, або викликати метод `[ReadableStreamInstance].resume()`, або відправити потік на запис викликом методу pipe()

{% code lineNumbers="true" %}
```javascript
import {readFile} from 'node:fs';

let stream = readFile.createReadStream('./files/data.txt')
setTimeout(
   () =>
       stream.on('data', (data) =>
           console.log(data.toString())
       ),
   3000
)
```
{% endcode %}

Переведення в режим очікування, якщо для даних, що зчитуються, немає призначення, здійснюється викликом методу `[ReadableStreamInstance].pause()`.

{% hint style="info" %}
У разі явного виклику методу **resume()** без наявності обробника події data всі дані потоку будуть втрачені
{% endhint %}

Події Node.js потоку Readable:

* **data** – отримання потоком даних;
* **resume** - ініціюється під час виклику методу resume();
* **pause** - ініціюється під час виклику методу pause();
* **close** - виникає при закритті джерела даних чи самого потоку;
* **end** - генерується, коли з джерела зчитано всі дані;
* **error** - виникнення у потоці помилки, обробнику аргументом передається об'єкт помилки.

### **Потік Writable**

Потік Writable відповідає за запис даних у вказане місце. Приклади потоків запису:

* надсилання HTTP запиту з клієнта на сервер;
* надсилання відповіді на HTTP запит із сервера на клієнт;
* запис даних у файл;
* надсилання даних по сокету.

Розглянемо приклад роботи з потоком Node.js Writable.

{% code lineNumbers="true" %}
```javascript
import {fs} from 'node:fs';

let writableStream = fs.createWriteStream(
   './files/data.txt'
)

writableStream.write('Something important data')
writableStream.end()

writableStream.on('finish', () =>
   console.log('Data was written.')
)
writableStream.on('error', (err) => console.log(err))
```
{% endcode %}

Запис у потік даних здійснюється за допомогою методу `[WritableStreamInstance].write()`, який приймає такі параметри:

* **data** - данні;
* **encode** - кодування (якщо дані рядкового типу);
* **callback** - функцію, яка буде викликана після запису переданих даних.

{% hint style="info" %}
Метод `[WritableStreamInstance].write()` може повернути false у тому випадку, якщо дані на запис надходитимуть у потік занадто швидко, тоді дані не встигатимуть записуватись і почнуть накопичуватися у внутрішньому буфері. Після досягнення ліміту буфера `[WritableStreamInstance].write()` поверне false, тим самим кажучи. що необхідно почекати запису даних, що надійшли. Коли буфер розвантажиться – буде згенеровано подію drain, і тоді можна буде продовжити запис.
{% endhint %}

Після закінчення роботи з потоком Writable викличте метод `[WritableStreamInstance].end()`, щоб вказати, що всі необхідні дані були записані. Виклик методу ініціює подію finish.

Якщо неправильно вказати шлях до файлу для запису даних, буде згенеровано подію error, обробнику якого аргументом буде передано об'єкт помилки.

`writableStream.on('error', (err) => console.log(err))` події Node.js потоку Writable:

* _drain_ - сигналізує можливості продовжити запис після переповнення внутрішнього буфера;
* _finish_ - ініціюється після виклику методу `[WritableStreamInstance].end()` та запису у вказане місце всіх даних;
* _close_ - виникає при закритті зазначеного ресурсу призначення даних чи самого потоку;
* _error_ - виникнення у потоці помилки, обробнику аргументом передається об'єкт помилки.

### Потік Duplex

У Node.js _Duplex_ потоками називаються ті потоки, які одночасно і _Readable_ і _Writable_. Прикладом Duplex потоку є передача даних по сокетах: відправлення даних однією стороною (запис) та прийняття їх іншою (читання).

### Потік Transform

Потоки _Transform_ є різновидом потоків _Duplex_, їхня відмінність полягає в тому, що перед віддачею вхідні дані видозмінюються (звідси і назва). Приклад потоку _Transform_ є процес шифрування або розшифрування даних.

### Метод pipe()

Для передачі даних з одного потоку до іншого, стосовно об'єкта потоку використовується метод _**pipe()**_. Він також виконує сполучну роль, дозволяючи поєднувати потоки між собою.

{% code lineNumbers="true" %}
```javascript
import {fs} from 'node:fs';


let readStream = fs.createReadStream('./files/from.txt')
let writeStream = fs.createWriteStream('./files/to.txt')

readStream.pipe(writeStream)
```
{% endcode %}

### **Process**

#### **P**rocess.stdin

Потік читання містить стандартний системний потік введення для вашої програми.

Якщо _**process.stdin**_ вказує на термінал(перевіряється викликом `tty.isatty())`, тоді вхідні дані буферизуватимуться рядково. Ви можете вимкнути рядкову буферизацію викликавши `process.stdin.setRawMode(true)`. Однак, майте на увазі, що в цьому випадку обробники системних натискань (таких як ^C і ^D) будуть видалені.

#### **Process.stdout**

Потік запису, що містить стандартний системний висновок для вашої програми. Надсилайте туди дані, якщо вам потрібно передати їх у _**stdout**_.

#### **Process.stderr**

Потік на запис, що містить стандартне системне виведення помилок для вашої програми. Надсилайте туди дані, якщо вам потрібно передати їх у _**stderr**_.

## Внутрішній пристрій потоків: буферизація даних, події, методи керування потоками.

### Буферизація

Як записуваний, так і читаний потоки зберігатимуть дані у внутрішньому буфері.

Обсяг потенційно буферизованих даних залежить від опції _highWaterMark_, переданої в конструктор потоку. Для звичайних потоків параметр _highWaterMark_ визначає загальну кількість байтів. Для потоків, що працюють в об’єктному режимі, _highWaterMark_ визначає загальну кількість об’єктів.

Дані буферизуються в доступних для читання потоках, коли реалізація викликає `stream.push(chunk)`. Якщо споживач потоку не викликає `stream.read()`, дані залишатимуться у внутрішній черзі, доки не будуть використані.

<figure><img src="https://lh5.googleusercontent.com/rYPWgjt65ZcoG-qkm39Oq_JyGEcywIslv6t2HB28q13fvB0QZUwOACmkehifrbyN2otIq3i-Y_mRnESh7B6D5ENDH5Tk570sFQKWFWCdhIFVfM4lMHH0uBQYz2jI5WSLslmr2RK51VgRLqMhx25dIL4nW68GfEc2ULAssvKImQwrf1BZTa20yY2v4w" alt=""><figcaption></figcaption></figure>

Щойно загальний розмір внутрішнього буфера читання досягне порогового значення, визначеного _highWaterMark_, потік тимчасово припинить читання даних із базового ресурсу, доки дані, які наразі буферизовані, не будуть використані (тобто потік припинить викликати внутрішній `readable._read( )` метод, який використовується для заповнення буфера читання).

Дані буферизуються в записуваних потоках, коли метод `writable.write(chunk)` викликається повторно. Хоча загальний розмір внутрішнього буфера запису нижчий за порогове значення, встановлене _highWaterMark_, виклики `writable.write()` повертатимуть true. Коли розмір внутрішнього буфера досягне або перевищить _highWaterMark_, буде повернено false.

{% hint style="info" %}
Ключова мета потокового API, зокрема методу `stream.pipe()`, полягає в тому, щоб обмежити буферизацію даних до прийнятних рівнів, щоб джерела та призначення з різними швидкостями не перевантажували доступну пам’ять.
{% endhint %}

Параметр _highWaterMark_ — це порогове значення, а не обмеження: воно визначає кількість даних, які потік буферизує, перш ніж перестане запитувати більше даних. Загалом він не передбачає суворого обмеження пам’яті. Конкретні реалізації потоку можуть застосувати суворіші обмеження, але робити це необов’язково.

Оскільки потоки _Duplex_ і _Transform_ доступні як для читання, так і для запису, кожен з них підтримує два окремих внутрішніх буфера, які використовуються для читання та запису, що дозволяє кожній стороні працювати незалежно від іншої, зберігаючи належний і ефективний потік даних. Наприклад, екземпляри _net.Socket_ — це дуплексні потоки, сторона для читання яких дозволяє споживати дані, отримані з сокета, а сторона для запису дозволяє записувати дані в сокет. Оскільки дані можуть записуватися в сокет швидше або повільніше, ніж дані приймаються, кожна сторона повинна працювати (і буферизуватися) незалежно від іншої.

Механіка внутрішньої буферизації є внутрішньою деталлю реалізації і може бути змінена в будь-який час. Однак для деяких розширених реалізацій внутрішні буфери можна отримати за допомогою `writable.writableBuffer` або `readable.readableBuffer`. Використання цих незадокументованих властивостей не рекомендується.

{% code lineNumbers="true" %}
```javascript
import {http} from 'node:http';

const server = http.createServer((req, res) => {
   // `req` is an http.IncomingMessage, which is a readable stream.
   // `res` is an http.ServerResponse, which is a writable stream.

   let body = '';
   // Get the data as utf8 strings.
   // If an encoding is not set, Buffer objects will be received.
   req.setEncoding('utf8');

   // Readable streams emit 'data' events once a listener is added.
   req.on('data', (chunk) => {
       body += chunk;
   });

   // The 'end' event indicates that the entire body has been received.
   req.on('end', () => {
       try {
           const data = JSON.parse(body);
           // Write back something interesting to the user:
           res.write(typeof data);
           res.end();
       } catch (er) {
           // uh oh! bad json!
           res.statusCode = 400;
           return res.end(`error: ${er.message}`);
       }
   });
});

server.listen(1337);

// $ curl localhost:1337 -d "{}"
// object
// $ curl localhost:1337 -d "\"foo\""
// string
// $ curl localhost:1337 -d "not json"
// error: Unexpected token o in JSON at position 1
```
{% endcode %}

Записуванні потоки (такі як res у прикладі) надають такі методи, як write() і end(), які використовуються для запису даних у потік.

Доступні для читання потоки використовують _API_ _EventEmitter_ для сповіщення коду програми, коли дані доступні для читання з потоку. Доступні дані можна зчитувати з потоку різними способами.

Потоки, доступні для запису та читання, використовують _API_ _EventEmitter_ різними способами для передачі поточного стану потоку.

Потоки _Duplex_ і _Transform_ доступні як для запису, так і для читання.

Програми, які або записують дані в потік, або споживають дані з потоку, не зобов’язані безпосередньо впроваджувати потокові інтерфейси, і, як правило, не буде причин викликати `import 'node:stream'`.

Розробники, які бажають реалізувати нові типи потоків, повинні звернутися до розділу [**API for stream implementers**](https://nodejs.org/api/stream.html#api-for-stream-implementers).

## **Тип даних Buffer для бінарних даних.**

Буфер є деякою областю пам'яті, яка використовується для тимчасового зберігання потоків даних операцій введення/виводу, зокрема це стосується файлової системи та роботи з мережею. У Node.js робота з буфером здійснюється за допомогою глобального класу _**Buffer**_, який дозволяє обробляти потоки бінарних даних. Оскільки клас глобальний, він може бути використаний у будь-якому місці програми без імпорту самого модуля.

**Приклад:**

Типовий приклад, в якому ви можете зіткнутися з буфером у дії, - це перегляд відео в інтернеті. Якщо ваше інтернет-з'єднання досить швидке, швидкість потоку досить висока для того, щоб негайно заповнити буфер відеопрогравача і дозволити показати відео, потім заповнити наступний буфер, і відправити його на перегляд - і так доти, доки передача відео не завершиться. Тут показаний приклад системи, де дані прибувають швидше, ніж обробляються.

<figure><img src="https://lh4.googleusercontent.com/s0ba6EbyttO2ugWJp5TQxR8jyXjDYKgI6aD5viXbxPt2HoxaojoY8NUfBqR9ESc4OBXlEJj-xV-ogavwO6ZOUt9naYmWiS4kHoQwZLny8_jC8gqA49EARlTXjq68dZNBBkBmGB7XN4uZUhToQDjOIbswqKl0W7cSVSjahbo5PgRC0JW8EsLuD9r3WQ" alt=""><figcaption></figcaption></figure>

### Створення

Для створення порожнього буфера розміром 10 байт використовуйте метод `Buffer.alloc()`.

{% code lineNumbers="true" %}
```javascript
Buffer.alloc(10); //<Buffer 00 00 00 00 00 00 00 00 00 00>
```
{% endcode %}

Після створення буфера його розмір не можна змінити.

Розмір буфера зберігається як `length`.

{% code lineNumbers="true" %}
```javascript
let buffer = Buffer.alloc(3);
buffer.length; //3
```
{% endcode %}

Щоб заповнити створюваний буфер значенням за замовчуванням, просто передайте це значення `Buffer.alloc()` другим параметром

{% code lineNumbers="true" %}
```javascript
Buffer.alloc(10, 'A'); //<Buffer 41 41 41 41 41 41 41 41 41 41>
Buffer.alloc(10, 'ABC'); //<Buffer 41 42 43 41 42 43 41 42 43 41>
```
{% endcode %}

Якщо значення, що передається за замовчуванням, менше розміру самого буфера, то воно буде повторюватися в ньому, поки повністю його не заповнить.

Для створення буфера відразу потрібного розміру в Node.js є метод `Buffer.from()`, який приймає рядок і створює буфер.

{% code lineNumbers="true" %}
```javascript
Buffer.from('ABCDE'); //<Buffer 41 42 43 44 45>
```
{% endcode %}

Другим необов'язковим параметром методу `Buffer.from()` можна передати кодування.

{% code lineNumbers="true" %}
```javascript
Buffer.from('ABCDE', 'base64'); //<Buffer 00 10 83>
```
{% endcode %}

### Запис

Щоб записати дані в порожній або вже заповнений буфер, використовуйте метод `[Buffer instance].write()`, який приймає такі параметри:

* рядок для запису;
* позицію, з якої потрібно розпочати запис;
* довжину від початкового рядка, який потрібно записати;
* кодування (за промовчанням `utf8` )

Обов'язковим аргументом є лише рядок запису.

{% code lineNumbers="true" %}
```javascript
//Запис в пустий буфер
let buffer1 = Buffer.alloc(3); //<Buffer 00 00 00>
buffer1.write('ABC'); //<Buffer 41 42 43>

//Перезапис заповненого буфера
let buffer2 = Buffer.from('ABC'); //<Buffer 41 42 43>
buffer2.write('XYZ'); //<Buffer 58 59 5a>
```
{% endcode %}

Приклад запису до буфера з додатковими параметрами.

{% code lineNumbers="true" %}
```javascript
let buffer = Buffer.alloc(3);

//зсув позиції
buffer.write('A', 1); //<Buffer 00 41 00>

//обмеження запису переданого рядка
buffer.write('ABC', 0, 2); //<Buffer 41 42 00>
```
{% endcode %}

Метод `[Buffer instance].write()` повертає довжину записаного в буфер рядка.

{% code lineNumbers="true" %}
```javascript
let buffer = Buffer.alloc(5);
console.log(buffer.write('ABC')); //3
```
{% endcode %}

### Читання

Для отримання даних із буфера в тому форматі, в якому вони в нього заносилися, в Node.js є метод `[Buffer instance].toString()`, який приймає такі необов'язкові параметри:

* кодування (за замовчуванням `utf8` );
* позицію, з якої потрібно розпочати читання;
* позицію, де закінчити читання.

{% code lineNumbers="true" %}
```javascript
let buffer = Buffer.from('ABC');
buffer.toString(); //ABC
buffer.toString('utf8', 1, 1); //B
```
{% endcode %}

### Перетворення на JSON

Об'єкт Node.js класу `Buffer` може бути перетворений на формат JSON за допомогою методу `[Buffer instance].toJSON()`

{% code lineNumbers="true" %}
```javascript
let buffer = Buffer.from('ABC');
buffer.toJSON().data; //[65, 66, 67]
```
{% endcode %}

### Buffer API <a href="#buffer-api" id="buffer-api"></a>

У Node.js клас `Buffer` надає ряд корисних методів, що полегшують роботу з буфером:

`Buffer.Encoding()` - приймає кодування та повертає `true`, якщо його використання припустимо при роботі з буфером;

{% code lineNumbers="true" %}
```javascript
Buffer.isEncoding('ascii'); //true
```
{% endcode %}

`Buffer.isBuffer()` - приймає дані та повертає `true`, якщо вони є екземпляром класу `Buffer`;

{% code lineNumbers="true" %}
```javascript
Buffer.isBuffer('ascii'); //false
```
{% endcode %}

`Buffer.byteLength()` - повертає довжину переданого рядка в байтах (це не те саме, що кількість символів у рядку), другим необов'язковим параметром можна передати кодування;

{% code lineNumbers="true" %}
```javascript
Buffer.byteLength('ascii'); // 5
Buffer.byteLength('ascii', 'base64'); //
```
{% endcode %}

`Buffer.concat()` - приймає масив об'єктів класу `Buffer` та поєднує їх в один, другим необов'язковим параметром можна передати довжину підсумкового буфера.

{% code lineNumbers="true" %}
```javascript
let buffer1 = Buffer.from('ABC');
let buffer2 = Buffer.from('CDE');
Buffer.conact([buffer1, buffer2], 5); //
Buffer.conact([buffer1, buffer2], 7); //
```
{% endcode %}

## Передача даних із потоку в потік, обробка помилок у ланцюгу.

Обробка помилок для звичайного та конвеєрного потоків У потоках ми обробляємо помилки, створюючи в потоці слухач подій помилок. Слухач запускається, як тільки в потоці з’являється помилка.

{% code lineNumbers="true" %}
```javascript
myStream.on('error', (err) => {
   console.log(err);
});
```
{% endcode %}

Для випадку обробки помилок у конвеєрних потоках розглянемо наступний фрагмент коду:

{% code lineNumbers="true" %}
```javascript
import { createReadStream } from 'fs';
import express from 'express';
const app = express();
app.get('/', (req, res) => {
   var readStream = createReadStream('./data.txt');
   readStream.pipe(res);

   readStream.on('error', (err) => {
       console.log('Error in read stream...');
   });
   res.on('error', (err) => {
       console.log('Error in write stream...');
   });

   setTimeout(() => {
       readStream.emit('end');
   }, 20);
});
app.listen(8000);
```
{% endcode %}

Для запиту HTTP ми створили потік читання для файлу та передали його в потік запису відповіді HTTP.

У коді ми закрили потік читання між потоками, і це призвело до ініціювання помилки в потоці запису для читання з потоку, якого більше не існує.

Запуск наведеного вище коду та створення HTTP-запиту до кінцевої точки генерує такий результат:

Помилка в потоці запису...

```
Error in write stream...
Error [ERR_STREAM_WRITE_AFTER_END]: write after end
   at write_ (_http_outgoing.js:572:17)
   at ServerResponse.write (_http_outgoing.js:567:10)
   at ReadStream.ondata (_stream_readable.js:709:20)
   at ReadStream.emit (events.js:198:13)
   at ReadStream.EventEmitter.emit (domain.js:448:20)
   at ReadStream.Readable.read (_stream_readable.js:504:10)
   at flow (_stream_readable.js:973:34)
   at ServerResponse.pipeOnDrainFunctionResult (_stream_readable.js:777:7)
   at ServerResponse.emit (events.js:198:13)
   at ServerResponse.EventEmitter.emit (domain.js:448:20)
```

Якщо ми маємо серію конвеєрних потоків у Node.js, ми повинні виконувати обробку помилок для кожного з потоків окремо.

{% code lineNumbers="true" %}
```javascript
a.pipe(b).pipe(c)
```
{% endcode %}

У Node канал не пересилає помилку до наступного каналу.

Щоб обробляти помилки у наведеному вище випадку конвеєрних потоків, ми повинні додати обробник помилок до кожного з потоків, як це:

{% code lineNumbers="true" %}
```javascript
a.on('error', err => console.log(err));
b.on('error', err => console.log(err));
c.on('error', err => console.log(err));
a.pipe(b).pipe(c)
```
{% endcode %}

У результаті, якщо в будь-якому з потоків виникне помилка, буде запущено відповідний обробник помилок, і процес не завершиться через необроблені помилки.

У результаті, якщо в будь-якому з потоків виникне помилка, буде запущено відповідний обробник помилок, і процес не завершиться через необроблені помилки.

Коли в якійсь із ланок була викликана подія 'error', і якщо потрібно про це повідомити «попередні» потоки в ланцюжку, для них також потрібно викликати подію 'error': `StreamClass.emit('error', err)` , і опрацювати ситуацію. Або скористатися модулем [pump](https://github.com/mafintosh/pump), за допомогою якого можна вирішити це питання.

### Події, доступні в потоці для запису

Нижче наведено події, які ми можемо прослуховувати в доступному для запису потокі.

#### drain

Припустимо, що у нас є сценарій, коли буфер потоку заповнений, і ми хочемо знати, коли в буфері є місце для продовження запису. У такому сценарії ми слухаємо подію зливу потоку.

Подія витоку запускається, як тільки потік буде відповідним для відновлення запису даних.

{% code lineNumbers="true" %}
```javascript
myStream.on('drain', () => {
   console.log('Stream writing can be resumed now...');
});
```
{% endcode %}

#### close

Подія запускається, як тільки потік закривається за допомогою функції `stream.close()` .

#### **finish**

Подія запускається після завершення трансляції.

#### pipe/unpipe

Події ініціюються, як тільки потік передається або не передається потоком.

{% code lineNumbers="true" %}
```javascript
readStream.on('pipe', data => {
   console.log('ReadStream: Piped on Stream...\n', data);
});
readStream.on('unpipe', data => {
   console.log('ReadStream: Unpiped on Stream...\n', data);
});
writableStream.on('pipe', data => {
   console.log('WriteStream: Piped on Stream...\n', data);
});
writableStream.on('unpipe', data => {
   console.log('WriteStream: Unpiped on Stream...\n', data);
});
readStream.pipe(writableStream);
```
{% endcode %}

Запуск наступного коду дасть результат у вигляді:

{% code lineNumbers="true" %}
```javascript
WriteStream: Piped on Stream...
ReadStream {
   _readableState:
       ReadableState {
       objectMode: false,
   ... (The complete Read Stream instance)
```
{% endcode %}

#### **cork/uncork**

Розглянемо сценарій, коли дані надходять із дуже низькою швидкістю, і ми хочемо, щоб деякі дані були буферизовані в потоці перед їх використанням. Ми можемо зробити це за допомогою методу пробки для записуванного потоку.

Викликаючи метод _**cork,**_ потік не записуватиме дані в пункт призначення, а зберігатиме дані в буфері.

Щоб скинути дані буфера до місця призначення, нам потрібно викликати метод _**uncork**_.

{% code lineNumbers="true" %}
```javascript
writableStream.cork();
writableStream.write('1');
writableStream.write('2');
writableStream.write('3');
process.nextTick(() => {
   writableStream.uncork();
});
```
{% endcode %}

У наведеному вище коді ми закрили потік. В результаті потік буде зупиняти потік даних, поки його не відкоркують.

Коли відкорковується у зворотному виклику nextTick, ми отримуємо 1 2 3 у буфері записуваного потоку, який передається до місця призначення.

Примітка. Якщо ми двічі викликаємо функцію cork(), щоб закупорити потік, нам доведеться двічі викликати функцію uncork(), щоб увімкнути потік даних із потоку.

Щоб прочитати про process.nextTick, прочитайте цю статтю.

Пояснення `process.nextTick`, `setImmediate і setTimeout` для фаз циклу подій У node js ви, мабуть, стикалися з будь-якою з перерахованих вище функцій. Справді знаєте різницю між... medium.com

#### **write**

Ця функція використовується для запису деяких даних у буфер потоку.

Якщо потік закрито, дані залишаться в буфері. Якщо потік відкоркований, він буде переданий до місця призначення. Ми використали функцію write у прикладі _cork/ucork_.

#### **close**

Ця функція використовується для закриття потоку. Як тільки буде викликана функція `close`, у потоці буде запущено слухач події _close_.

### **Підсумки**

За допомогою потоків можна вирішувати практично будь-яке завдання:

* збереження/читання даних у/з файлу чи бази даних;
* архівація файлів;
* шифрування даних;
* передачу даних через мережу (модулі обміну повідомленнями у реальному часі, реалізувати трансляцію відео, аудіо файлів)
